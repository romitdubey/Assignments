{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565c0957-ed5c-4055-90a8-904831d30b72",
   "metadata": {},
   "source": [
    "#### Q1. What is an ensemble technique in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1659208-df5d-4d49-a883-21a5fd49c035",
   "metadata": {},
   "source": [
    "Ans: **Ensemble techniques** in machine learning is a modeling approach that combines multiple individual models to improve the overall performance and accuracy of a predictive task. \n",
    "\n",
    "Ensemble methods are typically used when a single model is unable to capture the complexity of the data or is prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13057386-c2b2-4d82-9736-b4a2461c42d6",
   "metadata": {},
   "source": [
    "#### Q2. Why are ensemble techniques used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f16599-0f07-4f79-b99d-50d1b08bf902",
   "metadata": {},
   "source": [
    "Ans: \n",
    "- Ensemble techniques are used in machine learning to improve the overall accuracy, robustness, and stability of predictive models.\n",
    "\n",
    "- By combining multiple models that have different strengths and weaknesses, ensemble methods can often achieve better performance than any single model. \n",
    "\n",
    "- Additionally, ensemble methods can help reduce the risk of overfitting by introducing randomness into the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0364eb54-ac37-4cb8-a3df-9edec2afcb6e",
   "metadata": {},
   "source": [
    "#### Q3. What is bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fd22b-b733-4be1-9e6a-add09860aff6",
   "metadata": {},
   "source": [
    "Ans: **Bagging (Bootstrap Aggregation)** is an ensemble technique that involves training multiple independent models on different subsets of the training data, using random sampling with replacement. \n",
    "\n",
    "The final prediction is typically made by averaging the predictions of all the individual models. \n",
    "\n",
    "Bagging can help reduce overfitting by introducing randomness into the modeling process and can improve model accuracy by reducing variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63625f84-e106-448d-8608-04fe28746d5f",
   "metadata": {},
   "source": [
    "#### Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94551878-d24a-432e-aec5-3095e8e3fc64",
   "metadata": {},
   "source": [
    "Ans: **Boosting** is another ensemble technique that involves combining multiple weak models to create a strong model. \n",
    "\n",
    "In boosting, each model is trained on a weighted version of the training data, with more weight given to the examples that were previously misclassified. \n",
    "\n",
    "The final prediction is typically made by combining the predictions of all the individual models, with higher weight given to the models that perform better on the training data. \n",
    "\n",
    "Boosting can help improve model accuracy by reducing bias and can be particularly effective for complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662af46-ae3a-4636-aa79-ae5181a7e030",
   "metadata": {},
   "source": [
    "#### Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709615f2-5484-4310-8183-ae9b8d062d0b",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- *Improved accuracy*: Ensemble methods can often achieve better accuracy than any single model by combining multiple models with different strengths and weaknesses.\n",
    "- *Robustness*: Ensemble methods can be more robust to outliers and noisy data than single models.\n",
    "- *Reduced overfitting*: Ensemble methods can help reduce the risk of overfitting by introducing randomness into the modeling process.\n",
    "- *Better generalization*: Ensemble methods can often generalize better to new, unseen data than single models.\n",
    "- *Increased stability*: Ensemble methods can be more stable than single models, as the predictions are based on multiple independent models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472a2ee-289c-431c-b53b-0092edc90f05",
   "metadata": {},
   "source": [
    "#### Q6. Are ensemble techniques always better than individual models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125ca8c1-31d1-4979-b465-a7dd9b9ab5ad",
   "metadata": {},
   "source": [
    "Ans: Ensemble techniques are not always better than individual models. The effectiveness of ensemble methods depends on several factors, such as the quality and diversity of the individual models, the nature of the data, and the specific task at hand. \n",
    "\n",
    "In some cases, a well-designed single model may be able to achieve better performance than an ensemble method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578e651-f40c-46f2-b704-8f5665817405",
   "metadata": {},
   "source": [
    "#### Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec518356-c405-4037-94b6-d3450d762c5b",
   "metadata": {},
   "source": [
    "Ans: The confidence interval using bootstrap can be calculated by generating multiple bootstrap samples from the original dataset, calculating the statistic of interest (such as the mean or standard deviation) for each sample, and then calculating the confidence interval based on the distribution of the bootstrap statistics. \n",
    "\n",
    "A common approach is to use the percentile method, where the lower and upper bounds of the confidence interval are defined by the 2.5th and 97.5th percentiles of the bootstrap statistics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8373255-4233-46a8-bee1-fcaca1cc1daa",
   "metadata": {},
   "source": [
    "#### Q8. How does bootstrap work and What are the steps involved in bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93adf1c-9b52-414c-97bf-80efa70880f7",
   "metadata": {},
   "source": [
    "Ans: Bootstrap is a resampling technique that can be used to estimate the variability of a statistic or to construct confidence intervals for a population parameter. The steps involved in bootstrap are as follows:\n",
    "\n",
    "1. Take a random sample of size n (where n is the sample size) from the original dataset.\n",
    "\n",
    "2. Calculate the statistic of interest (such as the mean, median, or standard deviation) for the sample.\n",
    "\n",
    "3. Repeat steps 1 and 2 B times (where B is a large number, such as 1000 or 10000), each time taking a new random sample from the original dataset.\n",
    "\n",
    "4. Use the distribution of the B bootstrap statistics to estimate the variability of the statistic of interest or to construct a confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fc2f9-2af5-4fe8-b58b-f827b4ee713a",
   "metadata": {},
   "source": [
    "#### Q9. A researcher wants to estimate the mean height of a population of trees. They measure the height of a sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use bootstrap to estimate the 95% confidence interval for the population mean height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67fbb90-aee6-4774-add5-2eb2f5c1d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for population mean height: [14.33, 15.40]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "tree_heights = [15] * 50 + np.random.normal(0, 2, 50)\n",
    "\n",
    "num_bootstraps = 10000\n",
    "\n",
    "bootstrap_means = []\n",
    "for i in range(num_bootstraps):\n",
    "    bootstrap_sample = [random.choice(tree_heights) for _ in range(50)]  \n",
    "    bootstrap_mean = np.mean(bootstrap_sample)\n",
    "    bootstrap_means.append(bootstrap_mean)\n",
    "\n",
    "\n",
    "lower_bound = np.percentile(bootstrap_means, 2.5)\n",
    "upper_bound = np.percentile(bootstrap_means, 97.5)\n",
    "\n",
    "print(\"95% confidence interval for population mean height: [{:.2f}, {:.2f}]\".format(lower_bound, upper_bound))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
